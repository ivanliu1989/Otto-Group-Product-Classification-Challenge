gc()
gc()
library(doMC)
registerDoMC(cores = 1)
gc()
registerDoMC(cores = NULL)
install.packages(c("AICcmodavg", "deSolve", "Ecfun", "evtree", "highr", "knitr", "mboost", "mime", "minqa", "pcaPP", "raster", "rasterVis", "Rcpp", "RcppArmadillo", "rjags", "rjson", "rmarkdown", "RSQLite", "tis"))
install.packages(c("boot", "class", "cluster", "codetools", "KernSmooth", "MASS", "mgcv", "nlme"), lib="/Library/Frameworks/R.framework/Versions/3.1/Resources/library")
rm(list=ls(all=TRUE));gc(reset=TRUE);par(mfrow=c(1,1))
contributors()
gc()
gui.classify()
require(stylo)
gui.classify()
gui.oppose()
1906561661/log(901)
convert_to_chardate <- function(arrive_int) {
char_date <- format(reference_time + arrive_int * 60, format = '%Y %m %d %H %M', tz = 'UTC')
return(char_date)
}
reference_time <- as.POSIXct('2014 1 1 0 0', '%Y %m %d %H %M', tz = 'UTC')
convert_to_chardate(280232261)
install.packages("Rmpi")
install.packages(c("cluster", "KernSmooth", "mgcv"), lib="/Library/Frameworks/R.framework/Versions/3.1/Resources/library")
gc()
gc()
library(h2o)
localH2O <- h2o.init(ip = 'localhost', port = 54321, max_mem_size = '6g')
localH2O <- h2o.init(ip = 'localhost', port = 54321, max_mem_size = '6g')
h2o.clusterInfo(localH2O)
h2oServer <- h2o.init(ip="mr-0xd1", port = 53322)
h2o.addNewFeatures <- function(frame, timecol, intcols, factorcols, key) {
cat("\nFeature engineering for time column.")
hour <- frame[,timecol] %% 100
colnames(hour) <- "hour"
day <- ((frame[,timecol] - hour) %% 10000)/100
colnames(day) <- "day"
dow <- day %% 7
colnames(dow) <- "dayofweek"
frame <- cbind(frame[,-match(timecol,colnames(frame))], day, dow, hour, as.factor(day), as.factor(dow), as.factor(hour))
frame <- h2o.assign(frame, key)
h2o.rm(h2oServer, grep(pattern = "Last.value", x = h2o.ls(h2oServer)$Key, value = TRUE))
cat("\nFeature engineering for integer columns.")
newfactors <- c()
for (int in intcols) {
# turn integers into factors, keep top 100 levels
trim_integer_levels <- h2o.interaction(as.factor(frame[,int]), factors = 1, pairwise = FALSE, max_factors = 100, min_occurrence = 1)
newfactors <- c(newfactors, colnames(trim_integer_levels))
frame <- cbind(frame, trim_integer_levels)
frame <- h2o.assign(frame, key)
h2o.rm(h2oServer, grep(pattern = "Last.value", x = h2o.ls(h2oServer)$Key, value = TRUE))
}
cat("\nFeature engineering for factor columns.")
# create pair-wise interaction between factors, keep top 100 levels
factor_interactions <- h2o.interaction(frame, factors = c(newfactors,factorcols), pairwise = TRUE, max_factors = 100, min_occurrence = 2)
frame <- cbind(frame, factor_interactions)
# Store frame under designated key
frame <- h2o.assign(frame, key)
h2o.rm(h2oServer, grep(pattern = "Last.value", x = h2o.ls(h2oServer)$Key, value = TRUE))
frame
}
h2o.logLoss <- function(preds, resp) {
tpc <- preds
tpc <- h2o.exec(h2oServer,expr=ifelse(tpc > 1e-15, tpc, 1e-15))
tpc <- h2o.exec(h2oServer,expr=ifelse(tpc < 1-1e-15, tpc, 1-1e-15))
LL <- h2o.exec(h2oServer,expr=mean(-resp*log(tpc)-(1-resp)*log(1-tpc)))
h2o.rm(h2oServer, grep(pattern = "Last.value", x = h2o.ls(h2oServer)$Key, value = TRUE))
LL
}
library(h2o);library(stringr)
myseed=5816985749037550201
path <- "/Users/ivan/Work_directory/VAZU"
path_submission <- paste0(path,"./data/sampleSubmission.csv")
path_submission
path_submission <- paste0(path,"/data/sampleSubmission.csv")
path_train <- paste0(path,"/data/train_df_app_smooth.csv")
path_test <- paste0(path,"/data/test_df_app_smooth.csv")
cat("\nReading data.")
train_hex <- h2o.importFile(h2oServer, path = path_train)
h2oServer <- h2o.init(ip = 'localhost', port = 54321, max_mem_size = '6g')
h2o.clusterInfo(h2oServer)
train_hex <- h2o.importFile(h2oServer, path = path_train)
train_hex
a = .25
b = .21
c = .23
d = .19
(a+b+c+d)/4
4/(1/a + 1/b + 1/c + 1/d)
gc()
sqrt(15000000)
1/sqrt(15000000)
site <- 25800000
app <- 14500000
1:app
for i in 1:app {
print i
}
for (i in 1:app) {
print i
}
for (i in 1:app) {
print(i)
}
total_l <- 0
i%100000
i
i%%100000
site <- 25800000
app <- 14500000
total_l <- 0
for (i in 1:app) {
total_l <- total_l + 1/sqrt(i)
if (i%%100000 == 0){
print(i)
}
}
l_app <- total_l/app
l_app
total_l
1/sqrt(i)
site <- 25800000
app <- 14500000
total_l <- 0
for (i in 1:site) {
total_l <- total_l + 1/sqrt(i)
if (i%%100000 == 0){
print(i)
}
}
l_site <- total_l/site
l_site
install.packages("installr"); library(installr)
install.packages("installr")
install.packages("installr")
devtools::install_github('dmlc/xgboost',subdir='R-package')
devtools::install_github('dmlc/xgboost',subdir='R-package')
require(DiagrammeR)
devtools::install_github('rich-iannone/DiagrammeR')
devtools::install_github('rich-iannone/DiagrammeR')
install.packages('curl')
setwd('/Users/ivan/Work_directory/Otto-Group-Product-Classification-Challenge');
rm(list=ls());gc()
library(h2o);require(caret)
source('main/2_logloss_func.R')
load(file='data/target.RData')
load(file='data/raw_data_log.RData') # raw_data_log_scale.RData
localH2O <- h2o.init(ip = 'localhost', port = 54321, max_mem_size = '8g')
h2o.clusterInfo(localH2O)
trainIndex <- createDataPartition(train$target, p = .7,list = FALSE)
train_df <- train[trainIndex,];test_df  <- train[-trainIndex,]
train_df <- as.h2o(localH2O, train_df, key="train")
test_df <- as.h2o(localH2O, test_df, key="test")
independent <- colnames(train_df[,2:94])
dependent <- "target"
# fit <- h2o.gbm(y = dependent, x = independent, data = train_df,
#                n.trees = 300, interaction.depth = 6,
#                shrinkage = 0.05, distribution= "multinomial")
# n.bins, balance.classes, n.minobsinnode = 2,
fit <- h2o.deeplearning(y = dependent, x = independent, data = train_df,
classification=T,activation="Rectifier",#TanhWithDropout
#input_dropout_ratio = 0.2,hidden_dropout_ratios = c(0.5),
hidden=c(200),epochs=16,variable_importances=F,
override_with_best_model=T,nfolds=10,seed=8,loss='CrossEntropy',
l2=0.001,rate=0.1,nesterov_accelerated_gradient=F,shuffle_training_data=F)
independent <- colnames(train_df[,2:94])
head(train_df)
rm(list=ls());gc()
library(h2o);require(caret)
source('main/2_logloss_func.R')
load(file='data/target.RData')
load(file='data/raw_data_log.RData') # raw_data_log_scale.RData
localH2O <- h2o.init(ip = 'localhost', port = 54321, max_mem_size = '8g')
h2o.clusterInfo(localH2O)
trainIndex <- createDataPartition(train$target, p = .7,list = FALSE)
train_df <- train[trainIndex,];test_df  <- train[-trainIndex,]
train_df <- as.h2o(localH2O, train_df, key="train")
h2o.ls(localH2O)
h2o.rm(object= localH2O, keys= "DeepLearning_aa8d890913a2ad4d5f677dcad33849d2")
h2o.rm(object= localH2O, keys= "DeepLearning_aa8d890913a2ad4d5f677dcad33849d2_xval0")
h2o.rm(object= localH2O, keys= "DeepLearning_aa8d890913a2ad4d5f677dcad33849d2_xval1")
h2o.ls(localH2O)
h2o.rm(object= localH2O, keys= "DeepLearning_aa8d890913a2ad4d5f677dcad33849d2_xval2")
h2o.rm(object= localH2O)
h2o.ls(localH2O)
h2o.rm(object= localH2O, keys= "train")
h2o.rm(object= localH2O, keys= "test")
h2o.rm(object= localH2O, keys= "Last.value.0")
h2o.ls(localH2O)
h2o.rm(object= localH2O, keys= "DeepLearning_aa8d890913a2ad4d5f677dcad33849d2_xval2_train")
h2o.ls(localH2O)
h2o.rm(object= localH2O, keys= "DeepLearning_aa8d890913a2ad4d5f677dcad33849d2_xval2_holdout")
h2o.clusterInfo(localH2O)
