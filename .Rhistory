gc()
gc()
library(doMC)
registerDoMC(cores = 1)
gc()
registerDoMC(cores = NULL)
install.packages(c("AICcmodavg", "deSolve", "Ecfun", "evtree", "highr", "knitr", "mboost", "mime", "minqa", "pcaPP", "raster", "rasterVis", "Rcpp", "RcppArmadillo", "rjags", "rjson", "rmarkdown", "RSQLite", "tis"))
install.packages(c("boot", "class", "cluster", "codetools", "KernSmooth", "MASS", "mgcv", "nlme"), lib="/Library/Frameworks/R.framework/Versions/3.1/Resources/library")
rm(list=ls(all=TRUE));gc(reset=TRUE);par(mfrow=c(1,1))
contributors()
gc()
gui.classify()
require(stylo)
gui.classify()
gui.oppose()
1906561661/log(901)
convert_to_chardate <- function(arrive_int) {
char_date <- format(reference_time + arrive_int * 60, format = '%Y %m %d %H %M', tz = 'UTC')
return(char_date)
}
reference_time <- as.POSIXct('2014 1 1 0 0', '%Y %m %d %H %M', tz = 'UTC')
convert_to_chardate(280232261)
install.packages("Rmpi")
install.packages(c("cluster", "KernSmooth", "mgcv"), lib="/Library/Frameworks/R.framework/Versions/3.1/Resources/library")
gc()
gc()
library(h2o)
localH2O <- h2o.init(ip = 'localhost', port = 54321, max_mem_size = '6g')
localH2O <- h2o.init(ip = 'localhost', port = 54321, max_mem_size = '6g')
h2o.clusterInfo(localH2O)
h2oServer <- h2o.init(ip="mr-0xd1", port = 53322)
h2o.addNewFeatures <- function(frame, timecol, intcols, factorcols, key) {
cat("\nFeature engineering for time column.")
hour <- frame[,timecol] %% 100
colnames(hour) <- "hour"
day <- ((frame[,timecol] - hour) %% 10000)/100
colnames(day) <- "day"
dow <- day %% 7
colnames(dow) <- "dayofweek"
frame <- cbind(frame[,-match(timecol,colnames(frame))], day, dow, hour, as.factor(day), as.factor(dow), as.factor(hour))
frame <- h2o.assign(frame, key)
h2o.rm(h2oServer, grep(pattern = "Last.value", x = h2o.ls(h2oServer)$Key, value = TRUE))
cat("\nFeature engineering for integer columns.")
newfactors <- c()
for (int in intcols) {
# turn integers into factors, keep top 100 levels
trim_integer_levels <- h2o.interaction(as.factor(frame[,int]), factors = 1, pairwise = FALSE, max_factors = 100, min_occurrence = 1)
newfactors <- c(newfactors, colnames(trim_integer_levels))
frame <- cbind(frame, trim_integer_levels)
frame <- h2o.assign(frame, key)
h2o.rm(h2oServer, grep(pattern = "Last.value", x = h2o.ls(h2oServer)$Key, value = TRUE))
}
cat("\nFeature engineering for factor columns.")
# create pair-wise interaction between factors, keep top 100 levels
factor_interactions <- h2o.interaction(frame, factors = c(newfactors,factorcols), pairwise = TRUE, max_factors = 100, min_occurrence = 2)
frame <- cbind(frame, factor_interactions)
# Store frame under designated key
frame <- h2o.assign(frame, key)
h2o.rm(h2oServer, grep(pattern = "Last.value", x = h2o.ls(h2oServer)$Key, value = TRUE))
frame
}
h2o.logLoss <- function(preds, resp) {
tpc <- preds
tpc <- h2o.exec(h2oServer,expr=ifelse(tpc > 1e-15, tpc, 1e-15))
tpc <- h2o.exec(h2oServer,expr=ifelse(tpc < 1-1e-15, tpc, 1-1e-15))
LL <- h2o.exec(h2oServer,expr=mean(-resp*log(tpc)-(1-resp)*log(1-tpc)))
h2o.rm(h2oServer, grep(pattern = "Last.value", x = h2o.ls(h2oServer)$Key, value = TRUE))
LL
}
library(h2o);library(stringr)
myseed=5816985749037550201
path <- "/Users/ivan/Work_directory/VAZU"
path_submission <- paste0(path,"./data/sampleSubmission.csv")
path_submission
path_submission <- paste0(path,"/data/sampleSubmission.csv")
path_train <- paste0(path,"/data/train_df_app_smooth.csv")
path_test <- paste0(path,"/data/test_df_app_smooth.csv")
cat("\nReading data.")
train_hex <- h2o.importFile(h2oServer, path = path_train)
h2oServer <- h2o.init(ip = 'localhost', port = 54321, max_mem_size = '6g')
h2o.clusterInfo(h2oServer)
train_hex <- h2o.importFile(h2oServer, path = path_train)
train_hex
a = .25
b = .21
c = .23
d = .19
(a+b+c+d)/4
4/(1/a + 1/b + 1/c + 1/d)
gc()
sqrt(15000000)
1/sqrt(15000000)
site <- 25800000
app <- 14500000
1:app
for i in 1:app {
print i
}
for (i in 1:app) {
print i
}
for (i in 1:app) {
print(i)
}
total_l <- 0
i%100000
i
i%%100000
site <- 25800000
app <- 14500000
total_l <- 0
for (i in 1:app) {
total_l <- total_l + 1/sqrt(i)
if (i%%100000 == 0){
print(i)
}
}
l_app <- total_l/app
l_app
total_l
1/sqrt(i)
site <- 25800000
app <- 14500000
total_l <- 0
for (i in 1:site) {
total_l <- total_l + 1/sqrt(i)
if (i%%100000 == 0){
print(i)
}
}
l_site <- total_l/site
l_site
install.packages("installr"); library(installr)
install.packages("installr")
install.packages("installr")
devtools::install_github('dmlc/xgboost',subdir='R-package')
devtools::install_github('dmlc/xgboost',subdir='R-package')
require(DiagrammeR)
devtools::install_github('rich-iannone/DiagrammeR')
devtools::install_github('rich-iannone/DiagrammeR')
install.packages('curl')
h2o.shutdown(h2oServer)
require(caret);require(nnet);#require(deepnet)
setwd('/Users/ivan/Work_directory/Otto-Group-Product-Classification-Challenge')
require(caret);require(nnet);#require(deepnet)
source('main_R/2_logloss_func.R')
load(file='data/target.RData');load(file='data/raw_data_log_scale_range.RData')
pacFit <- preProcess(train, method = 'pca')
pacFit <- preProcess(train[,-which(names(train) %in% c("id","target"))], method = 'pca')
train[,-which(names(train) %in% c("id","target"))] <- predict(pacFit, train[,-which(names(train) %in% c("id","target"))])
trainIndex <- createDataPartition(train$target, p = .7,list = FALSE)
train_df <- train[trainIndex,];test_df  <- train[-trainIndex,]
train = train_df[,-which(names(train_df) %in% c("id"))] #train
test = test_df[,-which(names(test_df) %in% c("id"))] #test
dummies <- dummyVars(~target, data = train)
y <- predict(dummies, newdata = train)
x = rbind(train[,-which(names(train) %in% c("target"))],test[,-which(names(test) %in% c("target"))])#[,-which(names(test) %in% c("target"))])
x = as.matrix(x)
x = matrix(as.numeric(x),nrow(x),ncol(x))
trind = 1:nrow(y)
teind = (nrow(train)+1):nrow(x)
dtrain <- x[trind,]
dtest <- x[teind,]
head(dtrain)
fit <- nnet(y=y, x=dtrain, size=30, softmax=T, skip=T, decay=0.2, maxit=100, abstol=1.0e-4, reltol=1.0e-8, rang=1, MaxNWts=150000)
# linout, entropy, softmax, censored
# rang=1, Hess=T,weights=1,
val <- predict(fit, newdata=dtest,type = "raw")
target_df <- target[-trainIndex,]
b <- MulLogLoss(target_df,val)
s <- ifelse(b<best,"(*)","")
best <- ifelse(b<best,b,best)
print(paste0("parameter: ",n," | Score: ",b,s))
b
rm(list=ls());gc()
require(caret)
load(file='data/raw_data_multi.RData')
source(file='main_R/2_logloss_func.R')
train$sumNonZero <- apply(train[,2:94],1,function(x) sum(isZero(x)))
train$sumNonZero <- apply(train[,2:94],1,function(x) sum(which(x==0)))
head(train)
head(train[,2:94])
head(train[,2:95])
train$sumNonZero <- apply(train[,2:94],2,function(x) sum(which(x==0)))
train$sumNonZero <- apply(train[,2:94],1,function(x) sum(which(x==0)))
head(train)
which(x==0)
x <- train[,2:94]
which(x==0)
x <- train[1,2:94]
which(x==0)
sum(which(x==0))
train$sumNonZero <- apply(train[,2:94],1,function(x) length(which(x==0)))
head(train)
head(test)
test$sumNonZero <- apply(test[,2:94],1,function(x) length(which(x==0)))
head(train[,-which(names(train) %in% c("id","target"))])
train[,-which(names(train) %in% c("id","target"))] <- log(1+train[,-which(names(train) %in% c("id","target"))])
head(test[,-which(names(test) %in% c("id"))])
test[,-which(names(test) %in% c("id"))] <- log(1+test[,-which(names(test) %in% c("id"))])
head(train);head(test)
head(train)
head(train);
save(train,test,file='data/raw_data_log_newFeat.RData')
all_df <- rbind(train[,-which(names(train) %in% c("id","target"))], test[,-which(names(test) %in% c("id"))])
dim(train);dim(test);dim(all_df)
all_df <- apply(all_df,2,rangeScale)
all_df <- apply(all_df,2,center_scale)
head(all_df)
train[,-which(names(train) %in% c("id","target"))] <- all_df[1:nrow(train),]
test[,-which(names(test) %in% c("id"))] <- all_df[(nrow(train)+1):nrow(all_df),]
head(train)
head(test)
save(train,test,file='data/raw_data_log_scale_range_new_feat.RData')
rm(list=ls());gc()
require(caret);require(nnet);#require(deepnet)
source('main_R/2_logloss_func.R')
load(file='data/target.RData');load(file='data/raw_data_log_scale_range_new_feat.RData')
dim(train);set.seed(888);train <- shuffle(train)
trainIndex <- createDataPartition(train$target, p = .7,list = FALSE)
train_df <- train[trainIndex,];test_df  <- train[-trainIndex,]
train = train_df[,-which(names(train_df) %in% c("id"))] #train
test = test_df[,-which(names(test_df) %in% c("id"))] #test
dummies <- dummyVars(~target, data = train)
y <- predict(dummies, newdata = train)
x = rbind(train[,-which(names(train) %in% c("target"))],test[,-which(names(test) %in% c("target"))])#[,-which(names(test) %in% c("target"))])
x = as.matrix(x)
x = matrix(as.numeric(x),nrow(x),ncol(x))
trind = 1:nrow(y)
teind = (nrow(train)+1):nrow(x)
dtrain <- x[trind,]
dtest <- x[teind,]
n=1
fit <- nnet(y=y, x=dtrain, size=10, softmax=T, skip=T, decay=0.2, maxit=100, abstol=1.0e-4, reltol=1.0e-8, rang=1, MaxNWts=150000)
# linout, entropy, softmax, censored
# rang=1, Hess=T,weights=1,
val <- predict(fit, newdata=dtest,type = "raw")
target_df <- target[-trainIndex,]
b <- MulLogLoss(target_df,val)
s <- ifelse(b<best,"(*)","")
best <- ifelse(b<best,b,best)
print(paste0("parameter: ",n," | Score: ",b,s))
b
head(dtrain)
head(dtrain)
dim(dtrain)
dim(dtest)
rm(list=ls());gc()
require(caret);require(nnet);#require(deepnet)
source('main_R/2_logloss_func.R')
load(file='data/target.RData');load(file='data/raw_data_log_scale_range_new_feat.RData')
dim(train);set.seed(888);
# ### pca ###
# pacFit <- preProcess(train[,-which(names(train) %in% c("id","target"))], method = 'pca')
# train[,-which(names(train) %in% c("id","target"))] <- predict(pacFit, train[,-which(names(train) %in% c("id","target"))])
### split ###
trainIndex <- createDataPartition(train$target, p = .7,list = FALSE)
train_df <- train[trainIndex,];test_df  <- train[-trainIndex,]
train = train_df[,-which(names(train_df) %in% c("id"))] #train
test = test_df[,-which(names(test_df) %in% c("id"))] #test
train <- shuffle(train)
dummies <- dummyVars(~target, data = train)
y <- predict(dummies, newdata = train)
x = rbind(train[,-which(names(train) %in% c("target"))],test[,-which(names(test) %in% c("target"))])#[,-which(names(test) %in% c("target"))])
x = as.matrix(x)
x = matrix(as.numeric(x),nrow(x),ncol(x))
trind = 1:nrow(y)
teind = (nrow(train)+1):nrow(x)
dtrain <- x[trind,]
dtest <- x[teind,]
best <- 10
set.seed(888)
fit <- nnet(y=y, x=dtrain, size=10, softmax=T, skip=T, decay=0.2, maxit=100, abstol=1.0e-4, reltol=1.0e-8, rang=1, MaxNWts=150000)
# linout, entropy, softmax, censored
# rang=1, Hess=T,weights=1,
val <- predict(fit, newdata=dtest,type = "raw")
target_df <- target[-trainIndex,]
b <- MulLogLoss(target_df,val)
b
