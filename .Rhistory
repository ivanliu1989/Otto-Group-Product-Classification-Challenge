gc()
gc()
library(doMC)
registerDoMC(cores = 1)
gc()
registerDoMC(cores = NULL)
install.packages(c("AICcmodavg", "deSolve", "Ecfun", "evtree", "highr", "knitr", "mboost", "mime", "minqa", "pcaPP", "raster", "rasterVis", "Rcpp", "RcppArmadillo", "rjags", "rjson", "rmarkdown", "RSQLite", "tis"))
install.packages(c("boot", "class", "cluster", "codetools", "KernSmooth", "MASS", "mgcv", "nlme"), lib="/Library/Frameworks/R.framework/Versions/3.1/Resources/library")
rm(list=ls(all=TRUE));gc(reset=TRUE);par(mfrow=c(1,1))
contributors()
gc()
gui.classify()
require(stylo)
gui.classify()
gui.oppose()
1906561661/log(901)
convert_to_chardate <- function(arrive_int) {
char_date <- format(reference_time + arrive_int * 60, format = '%Y %m %d %H %M', tz = 'UTC')
return(char_date)
}
reference_time <- as.POSIXct('2014 1 1 0 0', '%Y %m %d %H %M', tz = 'UTC')
convert_to_chardate(280232261)
install.packages("Rmpi")
install.packages(c("cluster", "KernSmooth", "mgcv"), lib="/Library/Frameworks/R.framework/Versions/3.1/Resources/library")
gc()
gc()
library(h2o)
localH2O <- h2o.init(ip = 'localhost', port = 54321, max_mem_size = '6g')
localH2O <- h2o.init(ip = 'localhost', port = 54321, max_mem_size = '6g')
h2o.clusterInfo(localH2O)
h2oServer <- h2o.init(ip="mr-0xd1", port = 53322)
h2o.addNewFeatures <- function(frame, timecol, intcols, factorcols, key) {
cat("\nFeature engineering for time column.")
hour <- frame[,timecol] %% 100
colnames(hour) <- "hour"
day <- ((frame[,timecol] - hour) %% 10000)/100
colnames(day) <- "day"
dow <- day %% 7
colnames(dow) <- "dayofweek"
frame <- cbind(frame[,-match(timecol,colnames(frame))], day, dow, hour, as.factor(day), as.factor(dow), as.factor(hour))
frame <- h2o.assign(frame, key)
h2o.rm(h2oServer, grep(pattern = "Last.value", x = h2o.ls(h2oServer)$Key, value = TRUE))
cat("\nFeature engineering for integer columns.")
newfactors <- c()
for (int in intcols) {
# turn integers into factors, keep top 100 levels
trim_integer_levels <- h2o.interaction(as.factor(frame[,int]), factors = 1, pairwise = FALSE, max_factors = 100, min_occurrence = 1)
newfactors <- c(newfactors, colnames(trim_integer_levels))
frame <- cbind(frame, trim_integer_levels)
frame <- h2o.assign(frame, key)
h2o.rm(h2oServer, grep(pattern = "Last.value", x = h2o.ls(h2oServer)$Key, value = TRUE))
}
cat("\nFeature engineering for factor columns.")
# create pair-wise interaction between factors, keep top 100 levels
factor_interactions <- h2o.interaction(frame, factors = c(newfactors,factorcols), pairwise = TRUE, max_factors = 100, min_occurrence = 2)
frame <- cbind(frame, factor_interactions)
# Store frame under designated key
frame <- h2o.assign(frame, key)
h2o.rm(h2oServer, grep(pattern = "Last.value", x = h2o.ls(h2oServer)$Key, value = TRUE))
frame
}
h2o.logLoss <- function(preds, resp) {
tpc <- preds
tpc <- h2o.exec(h2oServer,expr=ifelse(tpc > 1e-15, tpc, 1e-15))
tpc <- h2o.exec(h2oServer,expr=ifelse(tpc < 1-1e-15, tpc, 1-1e-15))
LL <- h2o.exec(h2oServer,expr=mean(-resp*log(tpc)-(1-resp)*log(1-tpc)))
h2o.rm(h2oServer, grep(pattern = "Last.value", x = h2o.ls(h2oServer)$Key, value = TRUE))
LL
}
library(h2o);library(stringr)
myseed=5816985749037550201
path <- "/Users/ivan/Work_directory/VAZU"
path_submission <- paste0(path,"./data/sampleSubmission.csv")
path_submission
path_submission <- paste0(path,"/data/sampleSubmission.csv")
path_train <- paste0(path,"/data/train_df_app_smooth.csv")
path_test <- paste0(path,"/data/test_df_app_smooth.csv")
cat("\nReading data.")
train_hex <- h2o.importFile(h2oServer, path = path_train)
h2oServer <- h2o.init(ip = 'localhost', port = 54321, max_mem_size = '6g')
h2o.clusterInfo(h2oServer)
train_hex <- h2o.importFile(h2oServer, path = path_train)
train_hex
a = .25
b = .21
c = .23
d = .19
(a+b+c+d)/4
4/(1/a + 1/b + 1/c + 1/d)
gc()
sqrt(15000000)
1/sqrt(15000000)
site <- 25800000
app <- 14500000
1:app
for i in 1:app {
print i
}
for (i in 1:app) {
print i
}
for (i in 1:app) {
print(i)
}
total_l <- 0
i%100000
i
i%%100000
site <- 25800000
app <- 14500000
total_l <- 0
for (i in 1:app) {
total_l <- total_l + 1/sqrt(i)
if (i%%100000 == 0){
print(i)
}
}
l_app <- total_l/app
l_app
total_l
1/sqrt(i)
site <- 25800000
app <- 14500000
total_l <- 0
for (i in 1:site) {
total_l <- total_l + 1/sqrt(i)
if (i%%100000 == 0){
print(i)
}
}
l_site <- total_l/site
l_site
install.packages("installr"); library(installr)
install.packages("installr")
install.packages("installr")
devtools::install_github('dmlc/xgboost',subdir='R-package')
devtools::install_github('dmlc/xgboost',subdir='R-package')
require(DiagrammeR)
devtools::install_github('rich-iannone/DiagrammeR')
devtools::install_github('rich-iannone/DiagrammeR')
install.packages('curl')
library(h2o)
localH2O = h2o.init()
setwd('H:/Machine_Learning/Otto-Group-Product-Classification-Challenge');setwd('/Users/ivan/Work_directory/Otto-Group-Product-Classification-Challenge');setwd('C:/Users/Ivan.Liuyanfeng/Desktop/Data_Mining_Work_Space/Otto-Group-Product-Classification-Challenge')
rm(list=ls());gc()
setwd('H:/Machine_Learning/Otto-Group-Product-Classification-Challenge');setwd('/Users/ivan/Work_directory/Otto-Group-Product-Classification-Challenge');setwd('C:/Users/Ivan.Liuyanfeng/Desktop/Data_Mining_Work_Space/Otto-Group-Product-Classification-Challenge')
setwd('/Users/ivan/Work_directory/Otto-Group-Product-Classification-Challenge');
localH2O <- h2o.init(ip = 'localhost', port = 54321, max_mem_size = '8g')
h2o.clusterInfo(localH2O)
source('main/2_logloss_func.R')
load(file='data/target.RData')
load(file='data/raw_data_multi.RData')
train <- as.h2o(localH2O, train, key="train")
head(train)
class(train)
test <- as.h2o(localH2O, test, key="test")
colnames(train)
colnames(train[,1:20])
colnames(train)
independent <- colnames(train[,2:94])
dependent <- "target"
h2o.gbm(y = dependent, x = independent, data = train,
n.trees = 15, interaction.depth = 5,
n.minobsinnode = 2, shrinkage = 0.01, distribution= "multinomial")
fit
fit <- h2o.gbm(y = dependent, x = independent, data = train,
n.trees = 15, interaction.depth = 5,
n.minobsinnode = 2, shrinkage = 0.01, distribution= "multinomial")
pred <- h2o.predict(object = fit, newdata = test)
pred
fit <- h2o.deeplearning(y = dependent, x = independent, data = train,
classification=T,activation="Tanh",
hidden=c(10,10,10),epochs=12,variable_importances=T)
fit
pred <- h2o.predict(object = fit, newdata = test)
pred
pred_ensemble = format(pred[,2:10], digits=2,scientific=F) # shrink the size of submission
pred[,2:10]
pred_ensemble = format(as.data.frame(pred[,2:10]), digits=2,scientific=F) # shrink the size of submission
head(pred_ensemble)
pred_ensemble = data.frame(1:nrow(pred_ensemble),pred_ensemble)
names(pred_ensemble) = c('id', paste0('Class_',1:9))
write.csv(pred_ensemble,file='submission_max_047.csv', quote=FALSE,row.names=FALSE)
fit <- h2o.gbm(y = dependent, x = independent, data = train,
n.trees = 150, interaction.depth = 5,
n.minobsinnode = 2, shrinkage = 0.01, distribution= "multinomial")
fit
