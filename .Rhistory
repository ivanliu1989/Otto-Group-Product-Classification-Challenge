install.packages("installr");
library(installr)
updateR()
85+890+15+10
95/1000
install.packages(c("arules", "arulesViz", "Boruta", "Ecfun", "gender", "GGally", "gplots", "jsonlite", "multcomp", "plotmo", "prodlim", "RColorBrewer", "RcppArmadillo", "RCurl", "reshape2", "rFerns", "ROAuth", "rpart.plot", "rrcov", "seriation", "shiny", "VGAM"))
convert_to_minute <- function(arrival) {
arrive_time <- as.POSIXct(arrival, '%Y %m %d %H %M', tz = 'UTC')
age <- as.integer(difftime(arrive_time, reference_time, units = 'mins', tz = 'UTC'))
return(age)
}
reference_time <- as.POSIXct('2014 1 1 0 0', '%Y %m %d %H %M', tz = 'UTC')
convert_to_minute('2532 01 22 09 07')
convert_to_chardate <- function(arrive_int) {
char_date <- format(reference_time + arrive_int * 60, format = '%Y %m %d %H %M', tz = 'UTC')
return(char_date)
}
convert_to_chardate(9000000)
convert_to_chardate(17500000)
convert_to_chardate(175000000)
10000/24
126/394
log(0.123)
log(0.932)
log(-0.932)
install.packages(c("abind", "AER", "BH", "bibtex", "binda", "bootstrap", "BradleyTerry2", "C50", "cairoDevice", "car", "care", "caret", "checkpoint", "coda", "colorspace", "CORElearn", "corrgram", "devtools", "digest", "dplyr", "earth", "Ecfun", "extraTrees", "fdrtool", "flexmix", "forecast", "Formula", "frbs", "fscaret", "gbm", "gender", "GeneNet", "ggplot2", "gmm", "googleVis", "gplots", "gstat", "HDclassif", "HH", "Hmisc", "httr", "ipred", "kernlab", "knitr", "lava", "lazyeval", "LogicReg", "longitudinal", "manipulate", "MASS", "maxLik", "mboost", "multcomp", "mvoutlier", "NLP", "openNLP", "partDSA", "party", "partykit", "plotmo", "plotrix", "prabclus", "proxy", "pscl", "psych", "psychotools", "psychotree", "quantmod", "quantreg", "R.matlab", "R.methodsS3", "R.oo", "R.utils", "randomForestSRC", "rattle", "Rcmdr", "Rcpp", "RcppArmadillo", "RcppEigen", "RefManageR", "relimp", "rmarkdown", "ROAuth", "robustbase", "RODBC", "rpart.plot", "rstudioapi", "RWeka", "RWekajars", "shiny", "sp", "spacetime", "SparseM", "stabs", "stringdist", "swirl", "TH.data", "timeDate", "tseries", "TSP", "twitteR", "UsingR", "VGAM", "VGAMdata", "XLConnect", "zoo"))
setwd('C:/Users/Ivan.Liuyanfeng/Desktop/Data_Mining_Work_Space/Otto-Group-Product-Classification-Challenge')
setwd('C:/Users/Ivan.Liuyanfeng/Desktop/Data_Mining_Work_Space/Otto-Group-Product-Classification-Challenge')
rm(list=ls());gc()
require(caret);require(glmnet)
source('main/2_logloss_func.R')
load(file='data/target.RData')
load(file='data/raw_data_log.RData') # raw_data_log_scale.RData
dim(train);set.seed(888);train <- shuffle(train)
trainIndex <- createDataPartition(train$target, p = .7,list = FALSE)
train_df <- train[trainIndex,];test_df  <- train[-trainIndex,]
train = train_df[,-which(names(train_df) %in% c("id"))] #train
test = test_df[,-which(names(test_df) %in% c("id"))] #test
y = train[,'target']
y = gsub('Class_','',y)
y = as.integer(y)-1 #xgboost take features in [0,numOfClass)
x = rbind(train[,-which(names(train) %in% c("target"))],test[,-which(names(test) %in% c("target"))])#[,-which(names(test) %in% c("target"))])
x = as.matrix(x)
x = matrix(as.numeric(x),nrow(x),ncol(x))
trind = 1:length(y)
teind = (nrow(train)+1):nrow(x)
dtrain <- x[trind,]
dtest <- x[teind,]
fit <- glmnet(y=target[trainIndex,], x=dtrain, family="multinomial",alpha=1,standardize=T,
type.logistic="Newton", nlambda=100, intercept=T, maxit=10^5,type.multinomial="ungrouped")
#family="mgaussian" , #alpha=1 is the lasso penalty, and alpha=0 the ridge penalty
# ungrouped,multinomial
val <- predict(fit, newx=dtest,type = "response")
#     target_df <- target[-trainIndex,]
#     logloss <- LogLoss(target_df,val[,dim(val)[2]])
#     print(paste0(logloss, '\n'))
#     mul_val[,n] <- val[,dim(val)[2]]
#}
target_df <- target[-trainIndex,]
MulLogLoss(target_df,val[,,dim(val)[3]])
